{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d19f945",
   "metadata": {},
   "source": [
    "## 작사가 인공지능 만들기  \n",
    "lstm 모델을 기반으로 가사를 입력 했을 때 그 다음으로 올 가사를 작성하는 인공지능을 만드는 작업을 했다.\n",
    "데이터 전처리 전 데이터의 크기는 187088이다.  \n",
    "  \n",
    "동일한 파일이 있는지 확인하기 위해, 파일명을 100개만 출력하였다.  \n",
    "파일이름 중 Kanye_West.txt, kanye.txt, kanye-west.txt 등 내용이 같아 보이는 파일들이 보였다.    \n",
    "파일의 내용을 확인해보니 하나의 파일에 하나의 노래에 대한 가사가 저장된 것이 아니라    \n",
    "파일명과 동일한 가수의 여러 노래들이 저장되어 있었다.  \n",
    "따라서 비슷한 이름의 파일들을 비교하여 내용이 95%이상 일치 한다면 동일한 파일로 간주하고 하나는 제외하는 작업을 추가하였다.    \n",
    "아래의 코드는 아지트에서 인천 캠퍼스 학우 분의 코드를 참고하였다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b21a5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/lyricist/data/lyrics/leonard-cohen.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/lil-wayne.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/blink-182.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/bruce-springsteen.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/notorious_big.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/beatles.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/bob-dylan.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/alicia-keys.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/dr-seuss.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/radiohead.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/nickelback.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/prince.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/joni-mitchell.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/missy-elliott.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/dj-khaled.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/michael-jackson.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/janisjoplin.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/al-green.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/bruno-mars.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/cake.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/patti-smith.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/ludacris.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/lorde.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/kanye.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/Lil_Wayne.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/bjork.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/lin-manuel-miranda.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/dolly-parton.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/notorious-big.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/dickinson.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/Kanye_West.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/nirvana.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/britney-spears.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/disney.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/bieber.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/kanye-west.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/nicki-minaj.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/nursery_rhymes.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/paul-simon.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/bob-marley.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/amy-winehouse.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/rihanna.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/jimi-hendrix.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/lady-gaga.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/r-kelly.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/adele.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/johnny-cash.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/drake.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/eminem.txt\n",
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "#데이터 읽어오기\n",
    "import glob\n",
    "import os, re\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*' #파일경로 지정 \n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "cnt = 0\n",
    "for i in txt_list:\n",
    "    print(i) #파일 100개 출력 \n",
    "    cnt += 1\n",
    "    if cnt > 100:\n",
    "        break\n",
    "\n",
    "raw_corpus = [] #가사 담을 리스트 정의\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() \n",
    "        raw_corpus.extend(raw) #가사 한 줄씩 저장 \n",
    "        \n",
    "print(\"데이터 크기:\", len(raw_corpus)) #187088 파일 제거하기 전 데이터 크기 \n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b9f2a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/lyricist/data/lyrics/notorious_big.txt /aiffel/aiffel/lyricist/data/lyrics/notorious-big.txt\n",
      "/aiffel/aiffel/lyricist/data/lyrics/Kanye_West.txt /aiffel/aiffel/lyricist/data/lyrics/kanye-west.txt\n"
     ]
    }
   ],
   "source": [
    "def check_duplicate_lyrics(file1, file2):\n",
    "    txt1 = []\n",
    "    txt2 = []\n",
    "    with open(file1, \"r\", encoding=\"utf-8\") as f: #file1 한 줄씩 읽어오기\n",
    "        raw = f.read().splitlines()\n",
    "        txt1.extend(raw)\n",
    "    \n",
    "    with open(file2, \"r\" ,encoding=\"utf-8\") as f: #file2 한 줄씩 읽어오기\n",
    "        raw = f.read().splitlines()\n",
    "        txt2.extend(raw)\n",
    "    \n",
    "    txt1 = set(txt1) #txt1 중복 제거\n",
    "    txt2 = set(txt2) #txt2 중복 제거\n",
    "    diff = txt1.difference(txt2) #txt2와 다른 가사만 변수 diff에 넣기\n",
    "    return len(txt1) * 0.05 > len(diff) \n",
    "\n",
    "import itertools\n",
    "\n",
    "for a, b in itertools.combinations(txt_list, 2):#txt_list에서 원소 개수가 2개인 조합 뽑기\n",
    "    if check_duplicate_lyrics(a, b): #95% 일치한 경우 \n",
    "        print(a, b)\n",
    "        txt_list.remove(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f079209",
   "metadata": {},
   "source": [
    "notorious_big.txt와 notorious-big.txt의 내용이 95%이상 동일하다고 보고 notorious-big.txt 제외했고  \n",
    "Kanye_West.txt와 kanye-west.txt의 내용이 95%이상 동일하다고 보고 kanye-west.txt 파일을 데이터에서 제외했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1fe4578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "raw_corpus = [] #가사 담을 리스트 정의\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() \n",
    "        raw_corpus.extend(raw) #가사 한 줄씩 저장 \n",
    "        \n",
    "print(\"데이터 크기:\", len(raw_corpus)) \n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9bc9f29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>',\n",
       " '<start> you saw her bathing on the roof <end>',\n",
       " '<start> her beauty and the moonlight overthrew her <end>',\n",
       " '<start> she tied you <end>',\n",
       " '<start> to a kitchen chair <end>',\n",
       " '<start> she broke your throne , and she cut your hair <end>',\n",
       " '<start> and from your lips she drew the hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah you say i took the name in vain <end>',\n",
       " '<start> i don t even know the name <end>']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규표현식(Regex)을 이용한 데이터 전처리\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() #소문자로 바꾸고 양쪽 공백 지움\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) #특수문자 양쪽에 공백 넣기\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) #여러 공백 하나의 공백으로 바꿈\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿈\n",
    "    #sentence = re.sub(r\"[^a-zA-Z?.!¿]+\", \" \", sentence) # a-zA-Z?.!¿가 아닌 모든 문자를 하나의 공백으로 바꿈\n",
    "    #sentence = re.sub(r\"[^a-zA-Z?!,¿]+\", \" \", sentence) #155886\n",
    "    #sentence = re.sub(r\"[^a-zA-Z¿]+\", \" \", sentence) # a-zA-Z¿가 아닌 모든 문자를 하나의 공백으로 바꿈 => overfitting 발생 \n",
    "    sentence = sentence.strip() # 양쪽 공백 지움\n",
    "    sentence = '<start> ' + sentence + ' <end>' #문장 시작에 start 끝 end 추가 \n",
    "    return sentence\n",
    "\n",
    "corpus = [] #전처리 된 데이터 저장 장소\n",
    "\n",
    "#cnt = 0\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0:continue #공백 문자이면 건너뛰기\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)   \n",
    "\n",
    "corpus[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bce4791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_set = set(corpus) #중복되는 가사 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f38dfc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "da1d019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize:전처리된 단어들을 입력받아 tensor와 tokenizer 반환하는 함수\n",
    "def tokenize(corpus): \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=15000,#단어 15000개로 단어 사전 만들기 \n",
    "        filters=' ', #전처리 했기 때문에 filter 필요없음\n",
    "        split=' ', #공백 기준으로 단어 분리 \n",
    "        oov_token=\"<unk>\" #단어 사전에 포함 못하면 <unk>로 대체  \n",
    "    )\n",
    "\n",
    "    tokenizer.fit_on_texts(corpus)  \n",
    "    tensor = tokenizer.texts_to_sequences(corpus) #단어들을 숫자의 시퀀스 형태로 변환\n",
    "    #tensor = [x for x in tensor if len(x) <= 15]\n",
    "    \n",
    "    #padding='post':뒤에 0 붙이기\n",
    "    #max_len=15:시퀀스 길이 최대 15로 지정 => 토큰 길이가 15를 넘게 되면 잘림 \n",
    "    #tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post') \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15) \n",
    "\n",
    "    return tensor, tokenizer\n",
    "\n",
    "#tensor, tokenizer = tokenize(corpus_set) \n",
    "tensor, tokenizer = tokenize(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "09482809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175986, 15)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9731d0",
   "metadata": {},
   "source": [
    "check_duplicate_lyrics 함수거치고 set는 적용하지 않은 경우 tensor shape:(164512, 15), \n",
    "                                                           Source Train:(131609, 14), Target Train:(131609, 14)\n",
    "check_duplicate_lyrics 함수거치고 set는 적용한 경우 tensor shape:(164512, 15)\n",
    "                                                           Source Train:(131609, 14), Target Train:(131609, 14)  \n",
    "check_duplicate_lyrics 함수거치지 않고 set는 적용하지 않은 경우 tensor.shape:(175986, 15)  \n",
    "                                                           Source Train: (140788, 14), Target Train: (140788, 14)  \n",
    "check_duplicate_lyrics 함수거치지 않고 set는 적용한 경우 tensor.shape:(175986, 15)  \n",
    "                                                           Source Train: (140788, 14), Target Train: (140788, 14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2fea18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_input = tensor[:, :-1] #소스 문장\n",
    "tgt_input = tensor[:, 1:] #타겟 문장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c32512fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: (140788, 14)\n",
      "train label: (140788, 14)\n",
      "validation dataset: (35198, 14)\n",
      "validation label: (35198, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#train data, test data(20%)  분리 \n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                          tgt_input,\n",
    "                                                          test_size=0.2,       # 데이트셋 비율\n",
    "                                                          shuffle=True, \n",
    "                                                          random_state=42)\n",
    "\n",
    "print(\"train dataset:\", enc_train.shape)\n",
    "print(\"train label:\", dec_train.shape)\n",
    "print(\"validation dataset:\", enc_val.shape)\n",
    "print(\"validation label:\", dec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "76458809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 셋 객체 생성\n",
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1 #단어사전 15000개 + 포함 되지 않은 0:<pad> 포함하여 15001개\n",
    "\n",
    "#training data set 만들기  \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "#validation data set 만들기 \n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ca361fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "59f120b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "abcaf513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (140788, 14)\n",
      "Target Train: (140788, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "71367688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 설계\n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "embedding_size = 512 \n",
    "hidden_size = 2048\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "57d8ce71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 15001), dtype=float32, numpy=\n",
       "array([[[-7.26223661e-05,  1.26497151e-04,  4.75626148e-04, ...,\n",
       "          1.90099483e-04,  9.28074951e-05,  2.82949914e-04],\n",
       "        [ 1.59770701e-04,  1.29821201e-04,  8.70480610e-04, ...,\n",
       "          1.86664445e-04,  1.95050729e-04,  6.85614243e-04],\n",
       "        [ 3.10330011e-04,  1.35859504e-04,  9.54218034e-04, ...,\n",
       "          1.92492866e-04,  3.99787823e-04,  5.81416127e-04],\n",
       "        ...,\n",
       "        [-9.99067794e-04,  2.46352423e-03,  1.94784522e-03, ...,\n",
       "         -1.49393291e-03,  1.97466323e-03,  6.89141918e-04],\n",
       "        [-1.11425749e-03,  2.83004669e-03,  2.07325537e-03, ...,\n",
       "         -1.59573799e-03,  1.96282309e-03,  7.23199511e-04],\n",
       "        [-1.22180465e-03,  3.15000303e-03,  2.16650101e-03, ...,\n",
       "         -1.71365717e-03,  1.91523985e-03,  7.11723871e-04]],\n",
       "\n",
       "       [[-7.26223661e-05,  1.26497151e-04,  4.75626148e-04, ...,\n",
       "          1.90099483e-04,  9.28074951e-05,  2.82949914e-04],\n",
       "        [-2.62221110e-05,  5.56075305e-04,  9.66233958e-04, ...,\n",
       "          1.30716900e-04,  8.09974954e-05,  2.58513435e-04],\n",
       "        [ 9.44378116e-05,  1.02854008e-03,  1.42163737e-03, ...,\n",
       "         -1.63448407e-04,  1.44451406e-04,  8.04227602e-04],\n",
       "        ...,\n",
       "        [ 6.02326647e-04,  1.66919304e-03,  1.29630882e-03, ...,\n",
       "         -1.64662872e-03,  6.67571148e-04,  1.55042275e-04],\n",
       "        [ 4.64871002e-04,  1.73406361e-03,  1.50147791e-03, ...,\n",
       "         -1.63656787e-03,  9.43193852e-04,  2.99170439e-04],\n",
       "        [ 2.59967754e-04,  1.88705081e-03,  1.68689643e-03, ...,\n",
       "         -1.62707991e-03,  1.14249322e-03,  3.85744061e-04]],\n",
       "\n",
       "       [[-7.26223661e-05,  1.26497151e-04,  4.75626148e-04, ...,\n",
       "          1.90099483e-04,  9.28074951e-05,  2.82949914e-04],\n",
       "        [ 1.85164881e-05,  7.11180910e-05,  8.02309427e-04, ...,\n",
       "          2.32845821e-04,  4.42619319e-04,  1.36958595e-04],\n",
       "        [-2.03766922e-06,  1.64501995e-04,  8.77297658e-04, ...,\n",
       "          2.34947118e-04,  4.30703250e-04, -9.85223814e-05],\n",
       "        ...,\n",
       "        [ 1.57302304e-04,  2.54452287e-04,  1.20594609e-03, ...,\n",
       "         -1.07427058e-03,  4.61263990e-04,  2.88056850e-04],\n",
       "        [ 5.92075630e-05,  4.55788802e-04,  1.33005425e-03, ...,\n",
       "         -1.14964973e-03,  7.11199536e-04,  6.54627453e-04],\n",
       "        [-1.08665576e-04,  7.57749483e-04,  1.42807700e-03, ...,\n",
       "         -1.19394448e-03,  9.40712751e-04,  9.42847866e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-7.26223661e-05,  1.26497151e-04,  4.75626148e-04, ...,\n",
       "          1.90099483e-04,  9.28074951e-05,  2.82949914e-04],\n",
       "        [-8.17880864e-05,  3.08216375e-04,  8.13920458e-04, ...,\n",
       "          2.02723939e-04,  1.92340493e-04,  2.51496298e-04],\n",
       "        [-5.36774314e-05,  7.24965939e-04,  1.09286862e-03, ...,\n",
       "          4.22107041e-05, -8.83307512e-05,  1.88444494e-04],\n",
       "        ...,\n",
       "        [-8.08283221e-04,  1.95934623e-03,  1.90892746e-03, ...,\n",
       "         -7.02245918e-04,  1.55677123e-03,  7.41653203e-05],\n",
       "        [-9.89652821e-04,  2.27921619e-03,  1.97101687e-03, ...,\n",
       "         -8.53991369e-04,  1.59364298e-03,  1.33655922e-04],\n",
       "        [-1.15127547e-03,  2.58614286e-03,  2.02070898e-03, ...,\n",
       "         -1.04333425e-03,  1.58565631e-03,  1.52517983e-04]],\n",
       "\n",
       "       [[-7.26223661e-05,  1.26497151e-04,  4.75626148e-04, ...,\n",
       "          1.90099483e-04,  9.28074951e-05,  2.82949914e-04],\n",
       "        [-2.53666192e-04,  2.83127301e-04,  8.31198937e-04, ...,\n",
       "         -7.71711420e-05,  1.24878090e-04,  3.72514594e-04],\n",
       "        [ 2.15438791e-04,  5.48111799e-04,  1.11489487e-03, ...,\n",
       "         -3.85191932e-04,  2.34090548e-04,  6.02050335e-04],\n",
       "        ...,\n",
       "        [ 1.98366074e-03,  1.03858206e-03,  1.77116902e-03, ...,\n",
       "          2.02817100e-04,  4.92856954e-04,  1.93723035e-03],\n",
       "        [ 1.44301238e-03,  1.37252547e-03,  1.86763797e-03, ...,\n",
       "         -1.38404983e-04,  7.63641845e-04,  1.96096255e-03],\n",
       "        [ 9.19856422e-04,  1.73874665e-03,  1.94613938e-03, ...,\n",
       "         -4.58691968e-04,  9.86149651e-04,  1.90767995e-03]],\n",
       "\n",
       "       [[-7.26223661e-05,  1.26497151e-04,  4.75626148e-04, ...,\n",
       "          1.90099483e-04,  9.28074951e-05,  2.82949914e-04],\n",
       "        [-3.61744373e-04,  4.70171180e-05,  7.74698274e-04, ...,\n",
       "          7.22213736e-05,  1.55774469e-05,  5.24762319e-04],\n",
       "        [-6.12638716e-04, -3.45597946e-04,  9.17526952e-04, ...,\n",
       "          2.04151784e-05, -2.98206840e-04,  8.70423566e-04],\n",
       "        ...,\n",
       "        [-5.29125973e-04, -5.25935066e-05,  5.48906741e-04, ...,\n",
       "         -2.22453586e-04, -6.16488571e-04, -2.71285273e-04],\n",
       "        [-6.62746781e-04,  4.30663145e-04,  9.24325024e-04, ...,\n",
       "         -5.04725904e-04, -2.50504381e-04, -1.74039833e-05],\n",
       "        [-8.23838869e-04,  9.44558007e-04,  1.24989077e-03, ...,\n",
       "         -7.33011169e-04,  8.37884945e-05,  2.09488368e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tft_sample in train_dataset.take(1): break #데이터 셋에서 한 배치만 불러오는 방법 \n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d556ec8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      multiple                  7680512   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                multiple                  20979712  \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  30737049  \n",
      "=================================================================\n",
      "Total params: 92,959,897\n",
      "Trainable params: 92,959,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c438bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model compile\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, #from_logits:모델의 출력값이 문제에 맞게 normalize 된지 여부, 모델의 출력값이 확률이 아닌 값이 나온 경우 true로 지정\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62cdcfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "514/514 [==============================] - 263s 503ms/step - loss: 3.6268\n",
      "Epoch 2/10\n",
      "514/514 [==============================] - 267s 519ms/step - loss: 2.9782\n",
      "Epoch 3/10\n",
      "514/514 [==============================] - 267s 520ms/step - loss: 2.6765\n",
      "Epoch 4/10\n",
      "514/514 [==============================] - 268s 521ms/step - loss: 2.3981\n",
      "Epoch 5/10\n",
      "514/514 [==============================] - 267s 520ms/step - loss: 2.1378\n",
      "Epoch 6/10\n",
      "514/514 [==============================] - 268s 521ms/step - loss: 1.8952\n",
      "Epoch 7/10\n",
      "514/514 [==============================] - 268s 521ms/step - loss: 1.6744\n",
      "Epoch 8/10\n",
      "514/514 [==============================] - 268s 521ms/step - loss: 1.4762\n",
      "Epoch 9/10\n",
      "514/514 [==============================] - 268s 520ms/step - loss: 1.3016\n",
      "Epoch 10/10\n",
      "514/514 [==============================] - 267s 520ms/step - loss: 1.1571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7fd912f460>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case1: 중복된 파일 제거하고 가사간의 중복은 제거 하지 않은 경우 \n",
    "model.fit(train_dataset, epochs=10) #train data 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e01498f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "514/514 [==============================] - 265s 512ms/step - loss: 3.6171\n",
      "Epoch 2/10\n",
      "514/514 [==============================] - 269s 524ms/step - loss: 3.0371\n",
      "Epoch 3/10\n",
      "514/514 [==============================] - 270s 525ms/step - loss: 2.7869\n",
      "Epoch 4/10\n",
      "514/514 [==============================] - 270s 526ms/step - loss: 2.5660\n",
      "Epoch 5/10\n",
      "514/514 [==============================] - 270s 524ms/step - loss: 2.3594\n",
      "Epoch 6/10\n",
      "514/514 [==============================] - 270s 525ms/step - loss: 2.1638\n",
      "Epoch 7/10\n",
      "514/514 [==============================] - 269s 523ms/step - loss: 1.9774\n",
      "Epoch 8/10\n",
      "514/514 [==============================] - 267s 519ms/step - loss: 1.8019\n",
      "Epoch 9/10\n",
      "514/514 [==============================] - 267s 520ms/step - loss: 1.6360\n",
      "Epoch 10/10\n",
      "514/514 [==============================] - 267s 520ms/step - loss: 1.4796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7fe2a93f40>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case2: 중복된 파일 제거하고 가사간의 중복도 set로 제거한 경우\n",
    "model.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6ec79fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "549/549 [==============================] - 273s 494ms/step - loss: 3.6714\n",
      "Epoch 2/10\n",
      "549/549 [==============================] - 283s 516ms/step - loss: 3.0206\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 284s 517ms/step - loss: 2.7077\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 286s 520ms/step - loss: 2.4157\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 286s 520ms/step - loss: 2.1361\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 286s 521ms/step - loss: 1.8733\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 286s 521ms/step - loss: 1.6343\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 286s 521ms/step - loss: 1.4274\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 286s 521ms/step - loss: 1.2556\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 286s 521ms/step - loss: 1.1215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f4add9430>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case3: 중복된 파일 제거하지 않고 가사간의 중복도 set로 제거하지 않은 경우\n",
    "model.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0efa8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "549/549 [==============================] - 269s 487ms/step - loss: 3.6998\n",
      "Epoch 2/10\n",
      "549/549 [==============================] - 283s 515ms/step - loss: 3.1205\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 285s 519ms/step - loss: 2.8583\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 286s 520ms/step - loss: 2.6329\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 286s 520ms/step - loss: 2.4260\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 286s 521ms/step - loss: 2.2361\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 286s 520ms/step - loss: 2.0577\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 286s 520ms/step - loss: 1.8886\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 286s 520ms/step - loss: 1.7263\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 286s 520ms/step - loss: 1.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f4a097cd0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case4: 중복된 파일 제거하지 않고 가사간의 중복 set로 제거한 경우\n",
    "model.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "58f255bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    \n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence]) #init_sentence 텐서로 변환\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64) #test_input을 텐서로 변환 \n",
    "    end_token = tokenizer.word_index[\"<end>\"] #<end> 단어에 해당하는 키-쌍 딕셔너리 반환 \n",
    "\n",
    "    while True:\n",
    "        predict = model(test_tensor) #tensor로 변환된 데이터 입력 받음 \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] #예측된 값 중 가장 높은 확률인 word index 뽑아냄 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)#word index를 문장 뒤에 붙임\n",
    "        \n",
    "        if predict_word.numpy()[0] == end_token: break #모델이 <end>를 예측\n",
    "        if test_tensor.shape[1] >= max_len: break #max_len에 도달 \n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \" #word index를 단어로 하나씩 변환\n",
    "\n",
    "    return generated #완성된 문장 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "51da61a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> they said thou shall not be <end> '"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> They said \", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13d953",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "<b>모델 설명</b> batch_size는 256, 총 epoch 수는 10, 단어사전 15001개, 토큰 수 15, embedding_size = 512, hidden_size = 2048,  \n",
    "1개의 Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성된 LSTM model  \n",
    "\n",
    "<b>case1 check_duplicate_lyrics 함수거치고 set는 적용하지 않은 경우</b> embedding_size = 512, hidden_size = 2048, epoch5 일 때 loss가 2.2 이하로 떨어졌고 최종 loss는 1.1571였다. generate_text 함수에 \"hallelujah\"를 인자로 준 것은 종교적인 이유는 아니고 hallelujah가 들어간 문장이 87개로 꽤 많았기 때문이다. hallelujah는 주로 문장의 끝에 쓰이거나 단독으로 쓰이는 때가 많기 때문에 직관적으로 hallelujah 뒤에는 <end>가 올 것임을 예측할 수 있다. case1의 결과 hallelujah를 입력했을 때 예상대로 <end> 토큰이 나왔다.('<start> hallelujah <end> ')  \n",
    "  \n",
    "<b>case2 check_duplicate_lyrics 함수거치고 set는 적용한 경우(중복된 가사 제거)</b> embedding_size = 512, hidden_size = 2048, 최종 loss는 1.4796으로 case1 보다 loss가 더 컸다. generate_text에 \"I love\" 를 입력했을 때 lstm은 '<start> i love the way you lie <end> '를 작사했는데 음... \" i love the way you lie\"라는 결과가 잘 받아들여지지 않지만 아마도 가사 중에 이러한 문장이 많았기 때문이지 않을까 싶다.  \n",
    "    \n",
    "<b>case3 check_duplicate_lyrics 함수거치지 않고 set는 적용하지 않은 경우</b> embedding_size = 512, hidden_size = 2048, 최종 loss는 1.1215였는데 이는 check_duplicate_lyrics 함수를 거친 case1, 2 보다 낮다. 굳이 중복되는 파일을 삭제하지 않아도 충분히 낮은 loss를 얻은 이유가 무엇일지 궁금하다. 아마도 train data는 반복 학습을 할 수록 overfitting 되는 경향이 증가하니까 loss 값도 중복 되는 데이터가 많을 수록 줄어드는게 아닐까 싶다. generate_text의 결과는 '<start> she said honey if you want you can come with me <end> '로 꽤 도발적인 결과가 나왔다.  \n",
    "    \n",
    "<b>case4 check_duplicate_lyrics 함수거치지 않고 set는 적용한 경우</b> embedding_size = 512, hidden_size = 2048, 최종 loss는 1.5714였고 위 세가지 중 가장 loss가 높았다. generate_text의 결과는 '<start> they said thou shall not be <end> '라는 어색한 문장이 출력되었다.  \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
